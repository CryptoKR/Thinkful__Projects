{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wrangle your data. Get it into the notebook in the best form possible for your analysis and model building.\n",
    "\n",
    "* Explore your data. Make visualizations and conduct statistical analyses to explain what’s happening with your data, why it’s interesting, and what features you intend to take advantage of for your modeling.\n",
    "\n",
    "* Build a modeling pipeline. Your model should be build in a coherent pipeline of linked stages that is efficient and easy to implement.\n",
    "\n",
    "* Evaluate your models. You should have built multiple models, which you should thoroughly evaluate and compare via a robust analysis of residuals and failures.\n",
    "\n",
    "* Present and thoroughly explain your product. Describe your model in detail: why you chose it, why it works, what problem it solves, how it will run in a production like environment. What would you need to do to maintain it going forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import ccxt\n",
    "import os\n",
    "import statistics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Carter/Documents/Github/Thinkful__Projects/Final Capstone/'\n",
    "\n",
    "# DataFrames we've created\n",
    "historical_df = pd.read_csv(path + 'data/historical prices.csv')\n",
    "hodl_df = pd.read_csv(path + 'hodl.csv')\n",
    "rebalanced_df = pd.read_csv(path + 'rebalanced.csv')\n",
    "summary_df = pd.read_csv(path + 'summary.csv')\n",
    "\n",
    "# Date range used for simulations\n",
    "start_date, end_date = historical_data['date'][0], historical_data['date'][len(historical_data)-1]\n",
    "start_date = time.strftime('%m/%d/%Y', time.gmtime(start_date))\n",
    "end_date = time.strftime('%m/%d/%Y', time.gmtime(end_date))\n",
    "\n",
    "\n",
    "# list of coins used in each portfolio simulation\n",
    "coins = historical_data.columns[1:].tolist()\n",
    "cols = hodl_df.columns[1:]\n",
    "# For each simulation, make a list of the coins randomly chosen\n",
    "coin_lists = [i.split('-') for i in cols]\n",
    "\n",
    "print('Coins used in analysis', coins)\n",
    "print('Date range of simulation: {} - {}'.format(start_date, end_date)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End prices \n",
    "# Note: explain how taxes were calculated\n",
    "end_price_HODL = np.array(summary_df['end_price_HODL'] - summary_df['taxes_HODL'])\n",
    "end_price_rebalanced = np.array(summary_df['end_price_rebalanced'] - summary_df['taxes_rebalanced'])\n",
    "performance = list((end_price_rebalanced - end_price_HODL) / end_price_HODL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to compare coin impact on outperforming HODL\n",
    "df = pd.DataFrame(columns=coins)\n",
    "df['beat market'] = performance\n",
    "df['beat market'] = df['beat market'] > 0\n",
    "df.fillna(False, inplace=True)\n",
    "\n",
    "# Fill Dataframe with coins used for each simulation\n",
    "for i in range(len(coin_lists)):\n",
    "    for coin in coin_lists[i]:\n",
    "        df.loc[i, coin] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "tree = RandomForestClassifier()\n",
    "X = df[coins]\n",
    "Y = df['beat market']\n",
    "tree.fit(X, Y)\n",
    "\n",
    "feature_importance = tree.feature_importances_\n",
    "feature_importance = 100 * (feature_importance / max(feature_importance))\n",
    "temp = feature_importance.tolist()\n",
    "\n",
    "# Take only top 10 features\n",
    "top_feats = sorted(feature_importance,reverse=True)[:10]\n",
    "sorted_features = np.array([temp.index(feat) for feat in top_feats])\n",
    "pos = np.arange(sorted_features.shape[0]) + .5\n",
    "plt.barh(pos, feature_importance[sorted_features], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_features])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
