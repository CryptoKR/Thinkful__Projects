{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wrangle your data. Get it into the notebook in the best form possible for your analysis and model building.\n",
    "\n",
    "* Explore your data. Make visualizations and conduct statistical analyses to explain what’s happening with your data, why it’s interesting, and what features you intend to take advantage of for your modeling.\n",
    "\n",
    "* Build a modeling pipeline. Your model should be build in a coherent pipeline of linked stages that is efficient and easy to implement.\n",
    "\n",
    "* Evaluate your models. You should have built multiple models, which you should thoroughly evaluate and compare via a robust analysis of residuals and failures.\n",
    "\n",
    "* Present and thoroughly explain your product. Describe your model in detail: why you chose it, why it works, what problem it solves, how it will run in a production like environment. What would you need to do to maintain it going forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import ccxt\n",
    "import os\n",
    "import statistics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical market cap was downloaded from https://coin.dance/stats/marketcaphistorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1455840000, 1455926400, 1456099200, 1456185600, 1456272000,\n",
       "            1456358400, 1456444800, 1456531200, 1456617600, 1456704000,\n",
       "            ...\n",
       "            1539734400, 1539820800, 1539907200, 1539993600, 1540080000,\n",
       "            1540166400, 1540252800, 1540339200, 1540425600, 1540512000],\n",
       "           dtype='int64', name='date', length=975)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d4fd06452d0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m# Since all coins are still in BTC denomination, multiply by BTC price to get $ price\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/historical_prices.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python36\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "file = 'data/historical_market_cap_unformatted.xlsx'\n",
    "df = pd.read_excel(file)\n",
    "\n",
    "# convert date column to epoch time\n",
    "df = df.rename(columns={'Label': 'date'})\n",
    "\n",
    "dates = pd.DatetimeIndex(df['date'])\n",
    "dates = dates.astype(np.int64) / 10 **9\n",
    "\n",
    "df['date'] = dates\n",
    "\n",
    "# Total market cap\n",
    "df['Total Market Cap'] = df['Altcoin Market Cap'] + df['Bitcoin Market Cap']\n",
    "\n",
    "# Save file\n",
    "df.set_index('date', drop=True, inplace=True)\n",
    "df.to_csv('data/historical_market_cap.csv')\n",
    "\n",
    "\n",
    "# Use coins listed on Bittrex\n",
    "primary_exchange = ccxt.bittrex({'options': {'adjustForTimeDifference': True}})\n",
    "market = primary_exchange.load_markets()\n",
    "tickers = list(market.keys())\n",
    "\n",
    "# Since the tickers are formatted like 'ETH/BTC', split by the '/' and get a list of each coin once\n",
    "coins = set()\n",
    "[[coins.add(coin) for coin in ticker.split('/') if coin != 'BTC'] for ticker in tickers]\n",
    "coins = list(coins)\n",
    "\n",
    "# Now we have to convert all the coins back to coin/BTC to find prices.\n",
    "# Since we can't pull BTC/BTC, use BTC/USDT ticker\n",
    "tickers = [coin + '/BTC' for coin in coins]\n",
    "coins.insert(0, 'BTC')\n",
    "tickers.insert(0, 'BTC/USDT')\n",
    "\n",
    "# Dataframe to save coin price data\n",
    "df = pd.DataFrame(index=[list(dates)])\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Unfornately, some coins may not have a coin/BTC ratio, so only pull information if ticker exists\n",
    "    try:\n",
    "        data = np.array(primary_exchange.fetch_ohlcv(ticker, '1d'))[:, :2]\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    coin_prices = [price\\\n",
    "                   for day, price in data \\\n",
    "                   if time.strftime('%m/%d/%Y', time.localtime(day/1000)) in dates]\n",
    "\n",
    "    # Only add coin if it has price data for the whole time frame\n",
    "    if len(coin_prices) == len(dates):\n",
    "        df[ticker[:ticker.find('/')]] = coin_prices\n",
    "        \n",
    "# Since all coins are still in BTC denomination, multiply by BTC price to get $ price\n",
    "df[1:] *= df[0]\n",
    "df.to_csv('data/historical_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.455840e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.455926e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456099e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456186e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456272e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456358e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456445e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456531e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456618e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456704e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456790e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456877e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.456963e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457050e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457136e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457222e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457309e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457395e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457482e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457568e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457654e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457741e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457827e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.457914e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.458000e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.458086e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.458173e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.458259e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.458346e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.458432e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538006e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538093e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538179e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538266e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538352e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538438e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538525e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538611e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538698e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538784e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538870e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.538957e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539043e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539130e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539216e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539302e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539389e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539475e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539562e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539648e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539734e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539821e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539907e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.539994e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.540080e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.540166e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.540253e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.540339e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.540426e+09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.540512e+09</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>975 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(1455840000.0,), (1455926400.0,), (1456099200.0,), (1456185600.0,), (1456272000.0,), (1456358400.0,), (1456444800.0,), (1456531200.0,), (1456617600.0,), (1456704000.0,), (1456790400.0,), (1456876800.0,), (1456963200.0,), (1457049600.0,), (1457136000.0,), (1457222400.0,), (1457308800.0,), (1457395200.0,), (1457481600.0,), (1457568000.0,), (1457654400.0,), (1457740800.0,), (1457827200.0,), (1457913600.0,), (1458000000.0,), (1458086400.0,), (1458172800.0,), (1458259200.0,), (1458345600.0,), (1458432000.0,), (1458518400.0,), (1458604800.0,), (1458691200.0,), (1458777600.0,), (1458864000.0,), (1458950400.0,), (1459036800.0,), (1459123200.0,), (1459209600.0,), (1459296000.0,), (1459382400.0,), (1459468800.0,), (1459555200.0,), (1459641600.0,), (1459728000.0,), (1459814400.0,), (1459900800.0,), (1459987200.0,), (1460073600.0,), (1460160000.0,), (1460246400.0,), (1460332800.0,), (1460419200.0,), (1460505600.0,), (1460592000.0,), (1460678400.0,), (1460764800.0,), (1460851200.0,), (1460937600.0,), (1461024000.0,), (1461110400.0,), (1461196800.0,), (1461283200.0,), (1461369600.0,), (1461456000.0,), (1461542400.0,), (1461628800.0,), (1461715200.0,), (1461801600.0,), (1461888000.0,), (1461974400.0,), (1462060800.0,), (1462147200.0,), (1462233600.0,), (1462320000.0,), (1462406400.0,), (1462492800.0,), (1462579200.0,), (1462665600.0,), (1462752000.0,), (1462838400.0,), (1462924800.0,), (1463011200.0,), (1463097600.0,), (1463184000.0,), (1463270400.0,), (1463356800.0,), (1463443200.0,), (1463529600.0,), (1463616000.0,), (1463702400.0,), (1463788800.0,), (1463875200.0,), (1463961600.0,), (1464048000.0,), (1464134400.0,), (1464220800.0,), (1464307200.0,), (1464393600.0,), (1464480000.0,), ...]\n",
       "\n",
       "[975 rows x 0 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HODL and Rebalance functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_HODL(hist_prices):\n",
    "    sims = pd.DataFrame(index=sim_dates)\n",
    "\n",
    "    for sim_num in range(1000):\n",
    "        # Randomly select basket of coins\n",
    "        random_list = random.sample(range(len(coins)-1), num_coins)\n",
    "\n",
    "        # Determine amount of each coin bought on day 0\n",
    "        coin_amts = amt_each / hist_prices[0, random_list]\n",
    "\n",
    "        # Use coins as column name\n",
    "        col = '-'.join([coins[i] for i in random_list])\n",
    "\n",
    "        # Dot multiply list of coin amounts with array of historical prices of selected coins\n",
    "        sims[col] = hist_prices[:, random_list].dot(coin_amts)\n",
    "\n",
    "    simulations.to_csv('data/HODL.csv')\n",
    "    \n",
    "\n",
    "def simulate_rebalance(hodl_df, hist_prices):\n",
    "    \n",
    "    # Set the threshold of weight difference to trigger a trade\n",
    "    thresh = 0.05\n",
    "    avg_weight = 1 / num_coins\n",
    "    weighted_thresh = np.float32(avg_weight * thresh)\n",
    "    \n",
    "    # Exclude date column\n",
    "    cols = df.columns.tolist()\n",
    "    \n",
    "    # Convert to numpy for future vector multiplication\n",
    "    hodl_sims = np.array(hodl_df)\n",
    "    \n",
    "    # Arrays to be transformed to CSV's\n",
    "    sim_summary = [[] for x in range(len(cols))]\n",
    "    rebalance_sims = np.empty(shape=(len(cols), len(hist_prices)))\n",
    "    \n",
    "    # Use the same coin combinations as the HODL simulation\n",
    "    coin_lists = [col.split('-') for col in cols]\n",
    "    \n",
    "    # For each simulation, convert the symbol into the corresponding column # in historical_prices\n",
    "    coin_lists_indices = [[coins.index(coin) for coin in coin_list] for coin_list in coin_lists]\n",
    "    \n",
    "    # Loop for each simulation\n",
    "    for num, (col, coin_list, coin_list_index) in enumerate(zip(cols, coin_lists, coin_lists_indices)):\n",
    "        fees, trade_count, trades_eliminated, taxes_rebalanced = 0, 0, 0, 0\n",
    "        \n",
    "        # Starting list of our daily totals\n",
    "        daily_totals = [start_amt]\n",
    "        \n",
    "        # Reduce hist_prices array to only the coins used in the simulation (improves performace)\n",
    "        small_hist_prices = historical_prices[:, coin_list_index]\n",
    "        \n",
    "        # Initial purchase prices for coins\n",
    "        avg_prices = small_hist_prices[0].tolist()\n",
    "        \n",
    "        # Calculate starting coin amounts\n",
    "        coin_amts = amt_each / small_hist_prices[0]\n",
    "        \n",
    "        # Simulate each day (starting at day 1)\n",
    "        for day in range(1,len(hist_prices)):\n",
    "            while True:\n",
    "                \n",
    "                # Dollar value of each coin using the coin prices from that day\n",
    "                d_vals = small_hist_prices[day] * coin_amts\n",
    "                \n",
    "                d_val_sum = sum(d_vals)\n",
    "                l_index, h_index = d_vals.argmin(), d_vals.argmax()\n",
    "        \n",
    "                # See how far the lightest and heaviest coin weight deviates from average weight\n",
    "                weight_to_move = min([avg_weight - d_vals[l_index]/d_val_sum, d_vals[h_index]/d_val_sum - avg_weight])\n",
    "                if weighted_thresh > weight_to_move:\n",
    "                    break\n",
    "        \n",
    "                # Does a ticker for the coins exist? (Sometimes it doesn't: e.g. XRP/OMG)\n",
    "                # if it doesn't, it needs to convert to BTC first, which takes two trades\n",
    "                ratios = {coin_list[l_index] + '/' + coin_list[h_index], coin_list[h_index] + '/' + coin_list[l_index]}\n",
    "                ticker = ratios & tickers\n",
    "                \n",
    "                # Calculating fees - depends if we have one or two trades\n",
    "                rate = 0.0025\n",
    "                if not ticker:\n",
    "                    rate = 0.005\n",
    "                \n",
    "                d_amt = weight_to_move * d_val_sum\n",
    "                fees += (d_amt * rate)\n",
    "                \n",
    "                # Get coin quantities to buy/sell based on current market price\n",
    "                l_quantity = d_amt / small_hist_prices[day, l_index]\n",
    "                h_quantity = d_amt / small_hist_prices[day, h_index] * (1 + rate)\n",
    "                \n",
    "                price_diff = small_hist_prices[day, h_index] - avg_prices[h_index]\n",
    "                taxes_rebalanced += (price_diff * h_quantity * 0.25)\n",
    "                \n",
    "                # adjust avg purchase price for bought coin\n",
    "                avg_prices[l_index] = (avg_prices[l_index] * coin_amts[l_index] + small_hist_prices[day, l_index] * l_quantity)/(coin_amts[l_index] + l_quantity)\n",
    "                \n",
    "                # Adjust coin quantities\n",
    "                coin_amts[l_index] += l_quantity\n",
    "                coin_amts[h_index] -= h_quantity\n",
    "                \n",
    "            # document total portfolio value on that day\n",
    "            daily_totals.append(np.dot(small_hist_prices[day], coin_amts))\n",
    "            \n",
    "        # Document important features of the simulations\n",
    "        end_price_HODL = hodl_sims[len(hodl_sims)-1, num]\n",
    "        end_price_rebalanced = daily_totals[len(daily_totals)-1]\n",
    "        taxes_HODL = (end_price_HODL - 5000) * .25\n",
    "        \n",
    "        # Save simulation results \n",
    "        sim_summary[num] = [col, fees, taxes_HODL, end_price_HODL, taxes_rebalanced, end_price_rebalanced]\n",
    "        rebalance_sims[num] = daily_totals\n",
    "    \n",
    "    # Convert back to pandas DataFrame to save to CSV\n",
    "    rebalance_simulations = pd.DataFrame(np.transpose(rebalance_simulations), columns=cols, index=sim_dates)\n",
    "    rebalance_simulations.to_csv(file_path +  'rebalanced.csv')\n",
    "\n",
    "    simulation_summary = pd.DataFrame(\n",
    "        simulation_summary,\n",
    "        columns = [\n",
    "            'portfolio',\n",
    "            'total_fees',\n",
    "            'taxes_HODL',\n",
    "            'end_price_HODL',\n",
    "            'taxes_rebalanced',\n",
    "            'end_price_rebalanced'\n",
    "        ]\n",
    "    )    \n",
    "    simulation_summary.to_csv(file_path + 'summary.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_prices = pd.read_csv('data/historical_prices.csv')\n",
    "hist_m_cap = pd.read_csv('data/historical_market_cap.csv')\n",
    "\n",
    "# Convert to numpy for future vector functions\n",
    "hist_prices = np.array(hist_prices[coins])\n",
    "hist_m_cap = np.array(hist_m_cap)\n",
    "\n",
    "# Since we're looking for a year range, we'll only take corresponding start/end dates within the \n",
    "# date range that have a year difference\n",
    "start_dates = hist_m_cap[:len(hist_m_cap) - 365]\n",
    "end_dates = hist_m_cap[365:]\n",
    "\n",
    "# Subtract the ending market caps from each other, located in the 4th column\n",
    "cap_diffs = list(end_dates[:, 3] - start_dates[:, 3])\n",
    "    \n",
    "# Make sure there's an odd number of dates, so the median value can be indexed\n",
    "if len(cap_diffs) % 2 == 0:\n",
    "    cap_diffs.pop(len(cap_diffs)-1)\n",
    "        \n",
    "# Start date for simulations\n",
    "start_date = cap_diffs.index(np.median(cap_diffs))\n",
    "\n",
    "# Limit dataframe dates to the date range\n",
    "historical_prices = historical_prices[start_date:start_date + 365]\n",
    "sim_dates = sim_dates[start_date:start_date + 365]\n",
    "\n",
    "# Retrieve all current tickers on exchange\n",
    "exchange = ccxt.bittrex()\n",
    "tickers = set()\n",
    "[tickers.add(ticker) for ticker in exchange.fetch_tickers()]\n",
    "\n",
    "# Start with $5000 at day 0 price\n",
    "start_amt = 5000\n",
    "num_coins = 5\n",
    "amt_each = start_amt / num_coins\n",
    "\n",
    "simulate_HODL()\n",
    "hodl_df = pd.read_csv('data/HODL.csv')\n",
    "\n",
    "simulate_rebalance(hodl_df)\n",
    "rebalance_df = pd.read_csv('data/rebalanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames we've created\n",
    "historical_df = pd.read_csv(path + 'data/historical prices.csv')\n",
    "hodl_df = pd.read_csv(path + 'hodl.csv')\n",
    "rebalanced_df = pd.read_csv(path + 'rebalanced.csv')\n",
    "summary_df = pd.read_csv(path + 'summary.csv')\n",
    "\n",
    "# Date range used for simulations\n",
    "start_date, end_date = historical_data['date'][0], historical_data['date'][len(historical_data)-1]\n",
    "start_date = time.strftime('%m/%d/%Y', time.gmtime(start_date))\n",
    "end_date = time.strftime('%m/%d/%Y', time.gmtime(end_date))\n",
    "\n",
    "\n",
    "# list of coins used in each portfolio simulation\n",
    "coins = historical_data.columns[1:].tolist()\n",
    "cols = hodl_df.columns[1:]\n",
    "# For each simulation, make a list of the coins randomly chosen\n",
    "coin_lists = [i.split('-') for i in cols]\n",
    "\n",
    "print('Coins used in analysis', coins)\n",
    "print('Date range of simulation: {} - {}'.format(start_date, end_date)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End prices \n",
    "# Note: explain how taxes were calculated\n",
    "end_price_HODL = np.array(summary_df['end_price_HODL'] - summary_df['taxes_HODL'])\n",
    "end_price_rebalanced = np.array(summary_df['end_price_rebalanced'] - summary_df['taxes_rebalanced'])\n",
    "performance = list((end_price_rebalanced - end_price_HODL) / end_price_HODL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe to compare coin impact on outperforming HODL\n",
    "df = pd.DataFrame(columns=coins)\n",
    "df['beat market'] = performance\n",
    "df['beat market'] = df['beat market'] > 0\n",
    "df.fillna(False, inplace=True)\n",
    "\n",
    "# Fill Dataframe with coins used for each simulation\n",
    "for i in range(len(coin_lists)):\n",
    "    for coin in coin_lists[i]:\n",
    "        df.loc[i, coin] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "tree = RandomForestClassifier()\n",
    "X = df[coins]\n",
    "Y = df['beat market']\n",
    "tree.fit(X, Y)\n",
    "\n",
    "feature_importance = tree.feature_importances_\n",
    "feature_importance = 100 * (feature_importance / max(feature_importance))\n",
    "temp = feature_importance.tolist()\n",
    "\n",
    "# Take only top 10 features\n",
    "top_feats = sorted(feature_importance,reverse=True)[:10]\n",
    "sorted_features = np.array([temp.index(feat) for feat in top_feats])\n",
    "pos = np.arange(sorted_features.shape[0]) + .5\n",
    "plt.barh(pos, feature_importance[sorted_features], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_features])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
